{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# √âtape 1 : Charger et fusionner les fichiers\n",
    "train_df = pd.read_csv(\"kdd_train.csv\")\n",
    "test_df = pd.read_csv(\"kdd_test.csv\")\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"‚úÖ Fusion termin√©e : {df.shape[0]} lignes\")\n",
    "\n",
    "# √âtape 2 : Encodage des colonnes cat√©goriques\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"‚úÖ Colonnes cat√©goriques encod√©es :\", cat_cols)\n",
    "\n",
    "# √âtape 3 : Transformation de la colonne 'labels' ‚Üí 'target' (0 = normal, 1 = attaque)\n",
    "df['target'] = df['labels'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# √âtape 4 : Nettoyage final\n",
    "df.drop(columns=['labels'], inplace=True)\n",
    "\n",
    "# √âtape 5 : Sauvegarde\n",
    "df.to_csv(\"kdd_full_clean.csv\", index=False)\n",
    "print(\"‚úÖ Fichier final sauvegard√© sous : kdd_full_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc7e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion termin√©e : 148517 lignes\n",
      "‚úÖ Colonnes cat√©goriques encod√©es : ['protocol_type', 'service', 'flag']\n",
      "‚úÖ Mapping final :\n",
      "  0 ‚Üí dos\n",
      "  1 ‚Üí normal\n",
      "  2 ‚Üí other\n",
      "  3 ‚Üí probe\n",
      "  4 ‚Üí r2l\n",
      "  5 ‚Üí u2r\n",
      "‚úÖ Fichier sauvegard√© sous : kdd_full_clean_5classes.csv (classes DOS, PROBE, U2R, R2L, NORMAL)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# √âtape 1 : Charger et fusionner les fichiers\n",
    "train_df = pd.read_csv(\"kdd_train.csv\")\n",
    "test_df = pd.read_csv(\"kdd_test.csv\")\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"‚úÖ Fusion termin√©e : {df.shape[0]} lignes\")\n",
    "\n",
    "# √âtape 2 : Encodage des colonnes cat√©goriques\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"‚úÖ Colonnes cat√©goriques encod√©es :\", cat_cols)\n",
    "\n",
    "# √âtape 3 : Regroupement des labels en 5 super-cat√©gories\n",
    "dos = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'apache2', 'udpstorm', 'processtable', 'worm']\n",
    "probe = ['ipsweep', 'nmap', 'portsweep', 'satan', 'mscan', 'saint']\n",
    "u2r = ['buffer_overflow', 'loadmodule', 'perl', 'rootkit', 'xterm', 'ps', 'sqlattack']\n",
    "r2l = ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient', 'warezmaster',\n",
    "       'sendmail', 'named', 'snmpgetattack', 'snmpguess', 'xlock', 'xsnoop']\n",
    "\n",
    "def map_attack_type(label):\n",
    "    if label == 'normal':\n",
    "        return 'normal'\n",
    "    elif label in dos:\n",
    "        return 'dos'\n",
    "    elif label in probe:\n",
    "        return 'probe'\n",
    "    elif label in u2r:\n",
    "        return 'u2r'\n",
    "    elif label in r2l:\n",
    "        return 'r2l'\n",
    "    else:\n",
    "        return 'other'  # pour couverture compl√®te\n",
    "\n",
    "df['attack_class'] = df['labels'].apply(map_attack_type)\n",
    "\n",
    "# Encodage num√©rique final\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['attack_class'])\n",
    "\n",
    "# Affichage du mapping final\n",
    "print(\"‚úÖ Mapping final :\")\n",
    "for label, idx in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "    print(f\"  {idx} ‚Üí {label}\")\n",
    "\n",
    "# √âtape 4 : Nettoyage\n",
    "df.drop(columns=['labels', 'attack_class'], inplace=True)\n",
    "\n",
    "# √âtape 5 : Sauvegarde\n",
    "df.to_csv(\"kdd_full_clean_5classes.csv\", index=False)\n",
    "print(\"‚úÖ Fichier sauvegard√© sous : kdd_full_clean_5classes.csv (classes DOS, PROBE, U2R, R2L, NORMAL)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9749a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion termin√©e : 148517 lignes\n",
      "‚úÖ Colonnes cat√©goriques encod√©es : ['protocol_type', 'service', 'flag']\n",
      "‚úÖ Mapping des classes :\n",
      "  0 ‚Üí apache2\n",
      "  1 ‚Üí back\n",
      "  2 ‚Üí buffer_overflow\n",
      "  3 ‚Üí ftp_write\n",
      "  4 ‚Üí guess_passwd\n",
      "  5 ‚Üí httptunnel\n",
      "  6 ‚Üí imap\n",
      "  7 ‚Üí ipsweep\n",
      "  8 ‚Üí land\n",
      "  9 ‚Üí loadmodule\n",
      "  10 ‚Üí mailbomb\n",
      "  11 ‚Üí mscan\n",
      "  12 ‚Üí multihop\n",
      "  13 ‚Üí named\n",
      "  14 ‚Üí neptune\n",
      "  15 ‚Üí nmap\n",
      "  16 ‚Üí normal\n",
      "  17 ‚Üí perl\n",
      "  18 ‚Üí phf\n",
      "  19 ‚Üí pod\n",
      "  20 ‚Üí portsweep\n",
      "  21 ‚Üí processtable\n",
      "  22 ‚Üí ps\n",
      "  23 ‚Üí rootkit\n",
      "  24 ‚Üí saint\n",
      "  25 ‚Üí satan\n",
      "  26 ‚Üí sendmail\n",
      "  27 ‚Üí smurf\n",
      "  28 ‚Üí snmpgetattack\n",
      "  29 ‚Üí snmpguess\n",
      "  30 ‚Üí spy\n",
      "  31 ‚Üí teardrop\n",
      "  32 ‚Üí warezclient\n",
      "  33 ‚Üí warezmaster\n",
      "  34 ‚Üí xlock\n",
      "  35 ‚Üí xsnoop\n",
      "  36 ‚Üí xterm\n",
      "‚úÖ Fichier final multiclasse sauvegard√© sous : kdd_full_clean_multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# √âtape 1 : Charger et fusionner les fichiers\n",
    "train_df = pd.read_csv(\"kdd_train.csv\")\n",
    "test_df = pd.read_csv(\"kdd_test.csv\")\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"‚úÖ Fusion termin√©e : {df.shape[0]} lignes\")\n",
    "\n",
    "# √âtape 2 : Encodage des colonnes cat√©goriques\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"‚úÖ Colonnes cat√©goriques encod√©es :\", cat_cols)\n",
    "\n",
    "# √âtape 3 : Transformation de la colonne 'labels' ‚Üí 'target' multiclasse\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['labels'])\n",
    "\n",
    "# Sauvegarder le mapping label ‚Üí classe num√©rique\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"‚úÖ Mapping des classes :\")\n",
    "for label, idx in label_map.items():\n",
    "    print(f\"  {idx} ‚Üí {label}\")\n",
    "\n",
    "# √âtape 4 : Nettoyage final\n",
    "df.drop(columns=['labels'], inplace=True)\n",
    "\n",
    "# √âtape 5 : Sauvegarde\n",
    "df.to_csv(\"kdd_full_clean_multiclass.csv\", index=False)\n",
    "print(\"‚úÖ Fichier final multiclasse sauvegard√© sous : kdd_full_clean_multiclass.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typed_data_transformer_gmm import TypedDataTransformer\n",
    "import joblib\n",
    "\n",
    "# Load NSL-KDD dataset (Encoded and Important Features only)\n",
    "data = pd.read_csv('kdd_full_clean.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print('originail shape:', data.shape)\n",
    "data.head()\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "tdt = TypedDataTransformer(X)\n",
    "X_encoded = tdt.fit_transform(X)\n",
    "\n",
    "# Sauvegarder dans un fichier .pkl\n",
    "joblib.dump(tdt, \"typed_nslkdd_all_features.pkl\")\n",
    "print('originail shape:', X_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Chargement des fichiers :\n",
      "  ‚úÖ Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv : 170366 lignes\n",
      "  ‚úÖ Monday-WorkingHours.pcap_ISCX.csv : 529918 lignes\n",
      "  ‚úÖ Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv : 286467 lignes\n",
      "  ‚úÖ Tuesday-WorkingHours.pcap_ISCX.csv : 445909 lignes\n",
      "  ‚úÖ Friday-WorkingHours-Morning.pcap_ISCX.csv : 191033 lignes\n",
      "  ‚úÖ Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv : 225745 lignes\n",
      "  ‚úÖ Wednesday-workingHours.pcap_ISCX.csv : 692703 lignes\n",
      "  ‚úÖ Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv : 288602 lignes\n",
      "\n",
      "‚úÖ Fusion totale : 2830743 lignes\n",
      "‚úÖ Colonnes cat√©goriques encod√©es : []\n",
      "\n",
      "‚úÖ Mapping complet (Label ‚Üí target) :\n",
      "   0 ‚Üí BENIGN\n",
      "   1 ‚Üí Bot\n",
      "   2 ‚Üí DDoS\n",
      "   3 ‚Üí DoS GoldenEye\n",
      "   4 ‚Üí DoS Hulk\n",
      "   5 ‚Üí DoS Slowhttptest\n",
      "   6 ‚Üí DoS slowloris\n",
      "   7 ‚Üí FTP-Patator\n",
      "   8 ‚Üí Heartbleed\n",
      "   9 ‚Üí Infiltration\n",
      "  10 ‚Üí PortScan\n",
      "  11 ‚Üí SSH-Patator\n",
      "  12 ‚Üí Web Attack ÔøΩ Brute Force\n",
      "  13 ‚Üí Web Attack ÔøΩ Sql Injection\n",
      "  14 ‚Üí Web Attack ÔøΩ XSS\n",
      "\n",
      "‚úÖ R√©partition des classes :\n",
      "Label\n",
      "BENIGN                        2273097\n",
      "DoS Hulk                       231073\n",
      "PortScan                       158930\n",
      "DDoS                           128027\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7938\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1966\n",
      "Web Attack ÔøΩ Brute Force         1507\n",
      "Web Attack ÔøΩ XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack ÔøΩ Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Fichier sauvegard√© sous : cicids2017_clean_all_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "# === √âtape 1 : Chargement s√©curis√© et fusion ===\n",
    "folder = './cicids2017_csv_files'\n",
    "csv_files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "dataframes = []\n",
    "\n",
    "print(\"üìÇ Chargement des fichiers :\")\n",
    "for f in csv_files:\n",
    "    path = os.path.join(folder, f)\n",
    "    try:\n",
    "        df_temp = pd.read_csv(path)\n",
    "        dataframes.append(df_temp)\n",
    "        print(f\"  ‚úÖ {f} : {df_temp.shape[0]} lignes\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erreur dans {f} : {e}\")\n",
    "\n",
    "# Fusion\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "print(f\"\\n‚úÖ Fusion totale : {df.shape[0]} lignes\")\n",
    "\n",
    "# === √âtape 2 : Nettoyage des noms de colonnes ===\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# === √âtape 3 : Encodage des colonnes cat√©goriques ===\n",
    "cat_cols = ['Protocol', 'Flow ID', 'Source IP', 'Destination IP', 'Timestamp']\n",
    "cols_to_drop = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp']\n",
    "\n",
    "cat_cols = [col for col in cat_cols if col in df.columns]\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "print(f\"‚úÖ Colonnes cat√©goriques encod√©es : {cat_cols}\")\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "# === √âtape 4 : Encodage des labels ===\n",
    "if 'Label' in df.columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['target'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "    print(\"\\n‚úÖ Mapping complet (Label ‚Üí target) :\")\n",
    "    for label, idx in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "        print(f\"  {idx:2d} ‚Üí {label}\")\n",
    "\n",
    "    print(\"\\n‚úÖ R√©partition des classes :\")\n",
    "    print(df['Label'].value_counts())\n",
    "\n",
    "    df.drop(columns=['Label'], inplace=True)\n",
    "else:\n",
    "    print(\"‚ùå La colonne 'Label' est absente du DataFrame apr√®s fusion !\")\n",
    "# === Supprimer les lignes contenant des NaN et inf ===\n",
    "df = df.dropna()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# === √âtape 5 : Sauvegarde ===\n",
    "df.to_csv(\"cicids2017_clean_all_labels.csv\", index=False)\n",
    "print(\"\\n‚úÖ Fichier sauvegard√© sous : cicids2017_clean_all_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff550586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Donn√©es charg√©es avec succ√®s\n",
      "Original shape: (2827876, 79)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typed_data_transformer_gmm import TypedDataTransformer\n",
    "import joblib\n",
    "\n",
    "# === √âtape 1 : Charger les donn√©es nettoy√©es (avec classes ind√©pendantes) ===\n",
    "data = pd.read_csv('./cicids2017_clean_all_labels.csv')\n",
    "\n",
    "print('‚úÖ Donn√©es charg√©es avec succ√®s')\n",
    "print('Original shape:', data.shape)\n",
    "\n",
    "# === √âtape 2 : S√©paration features / target ===\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "# === √âtape 3 : Encodage intelligent avec TypedDataTransformer ===\n",
    "tdt = TypedDataTransformer(X)\n",
    "X_encoded = tdt.fit_transform(X)\n",
    "\n",
    "print('‚úÖ Transformation typ√©e r√©alis√©e')\n",
    "print('Encoded shape:', X_encoded.shape)\n",
    "\n",
    "# === √âtape 4 : Sauvegarde du transformeur ===\n",
    "joblib.dump(tdt, \"typed_cicids2017_all_features.pkl\")\n",
    "print('‚úÖ Transformeur sauvegard√© sous : typed_cicids2017_all_features.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
