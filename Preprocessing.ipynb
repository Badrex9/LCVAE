{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Étape 1 : Charger et fusionner les fichiers\n",
    "train_df = pd.read_csv(\"kdd_train.csv\")\n",
    "test_df = pd.read_csv(\"kdd_test.csv\")\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"✅ Fusion terminée : {df.shape[0]} lignes\")\n",
    "\n",
    "# Étape 2 : Encodage des colonnes catégoriques\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"✅ Colonnes catégoriques encodées :\", cat_cols)\n",
    "\n",
    "# Étape 3 : Transformation de la colonne 'labels' → 'target' (0 = normal, 1 = attaque)\n",
    "df['target'] = df['labels'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# Étape 4 : Nettoyage final\n",
    "df.drop(columns=['labels'], inplace=True)\n",
    "\n",
    "# Étape 5 : Sauvegarde\n",
    "df.to_csv(\"kdd_full_clean.csv\", index=False)\n",
    "print(\"✅ Fichier final sauvegardé sous : kdd_full_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc7e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fusion terminée : 148517 lignes\n",
      "✅ Colonnes catégoriques encodées : ['protocol_type', 'service', 'flag']\n",
      "✅ Mapping final :\n",
      "  0 → dos\n",
      "  1 → normal\n",
      "  2 → other\n",
      "  3 → probe\n",
      "  4 → r2l\n",
      "  5 → u2r\n",
      "✅ Fichier sauvegardé sous : kdd_full_clean_5classes.csv (classes DOS, PROBE, U2R, R2L, NORMAL)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Étape 1 : Charger et fusionner les fichiers\n",
    "train_df = pd.read_csv(\"kdd_train.csv\")\n",
    "test_df = pd.read_csv(\"kdd_test.csv\")\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"✅ Fusion terminée : {df.shape[0]} lignes\")\n",
    "\n",
    "# Étape 2 : Encodage des colonnes catégoriques\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"✅ Colonnes catégoriques encodées :\", cat_cols)\n",
    "\n",
    "# Étape 3 : Regroupement des labels en 5 super-catégories\n",
    "dos = ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'apache2', 'udpstorm', 'processtable', 'worm']\n",
    "probe = ['ipsweep', 'nmap', 'portsweep', 'satan', 'mscan', 'saint']\n",
    "u2r = ['buffer_overflow', 'loadmodule', 'perl', 'rootkit', 'xterm', 'ps', 'sqlattack']\n",
    "r2l = ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient', 'warezmaster',\n",
    "       'sendmail', 'named', 'snmpgetattack', 'snmpguess', 'xlock', 'xsnoop']\n",
    "\n",
    "def map_attack_type(label):\n",
    "    if label == 'normal':\n",
    "        return 'normal'\n",
    "    elif label in dos:\n",
    "        return 'dos'\n",
    "    elif label in probe:\n",
    "        return 'probe'\n",
    "    elif label in u2r:\n",
    "        return 'u2r'\n",
    "    elif label in r2l:\n",
    "        return 'r2l'\n",
    "    else:\n",
    "        return 'other'  # pour couverture complète\n",
    "\n",
    "df['attack_class'] = df['labels'].apply(map_attack_type)\n",
    "\n",
    "# Encodage numérique final\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['attack_class'])\n",
    "\n",
    "# Affichage du mapping final\n",
    "print(\"✅ Mapping final :\")\n",
    "for label, idx in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "    print(f\"  {idx} → {label}\")\n",
    "\n",
    "# Étape 4 : Nettoyage\n",
    "df.drop(columns=['labels', 'attack_class'], inplace=True)\n",
    "\n",
    "# Étape 5 : Sauvegarde\n",
    "df.to_csv(\"kdd_full_clean_5classes.csv\", index=False)\n",
    "print(\"✅ Fichier sauvegardé sous : kdd_full_clean_5classes.csv (classes DOS, PROBE, U2R, R2L, NORMAL)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9749a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fusion terminée : 148517 lignes\n",
      "✅ Colonnes catégoriques encodées : ['protocol_type', 'service', 'flag']\n",
      "✅ Mapping des classes :\n",
      "  0 → apache2\n",
      "  1 → back\n",
      "  2 → buffer_overflow\n",
      "  3 → ftp_write\n",
      "  4 → guess_passwd\n",
      "  5 → httptunnel\n",
      "  6 → imap\n",
      "  7 → ipsweep\n",
      "  8 → land\n",
      "  9 → loadmodule\n",
      "  10 → mailbomb\n",
      "  11 → mscan\n",
      "  12 → multihop\n",
      "  13 → named\n",
      "  14 → neptune\n",
      "  15 → nmap\n",
      "  16 → normal\n",
      "  17 → perl\n",
      "  18 → phf\n",
      "  19 → pod\n",
      "  20 → portsweep\n",
      "  21 → processtable\n",
      "  22 → ps\n",
      "  23 → rootkit\n",
      "  24 → saint\n",
      "  25 → satan\n",
      "  26 → sendmail\n",
      "  27 → smurf\n",
      "  28 → snmpgetattack\n",
      "  29 → snmpguess\n",
      "  30 → spy\n",
      "  31 → teardrop\n",
      "  32 → warezclient\n",
      "  33 → warezmaster\n",
      "  34 → xlock\n",
      "  35 → xsnoop\n",
      "  36 → xterm\n",
      "✅ Fichier final multiclasse sauvegardé sous : kdd_full_clean_multiclass.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Étape 1 : Charger et fusionner les fichiers\n",
    "train_df = pd.read_csv(\"kdd_train.csv\")\n",
    "test_df = pd.read_csv(\"kdd_test.csv\")\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print(f\"✅ Fusion terminée : {df.shape[0]} lignes\")\n",
    "\n",
    "# Étape 2 : Encodage des colonnes catégoriques\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"✅ Colonnes catégoriques encodées :\", cat_cols)\n",
    "\n",
    "# Étape 3 : Transformation de la colonne 'labels' → 'target' multiclasse\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['labels'])\n",
    "\n",
    "# Sauvegarder le mapping label → classe numérique\n",
    "label_map = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"✅ Mapping des classes :\")\n",
    "for label, idx in label_map.items():\n",
    "    print(f\"  {idx} → {label}\")\n",
    "\n",
    "# Étape 4 : Nettoyage final\n",
    "df.drop(columns=['labels'], inplace=True)\n",
    "\n",
    "# Étape 5 : Sauvegarde\n",
    "df.to_csv(\"kdd_full_clean_multiclass.csv\", index=False)\n",
    "print(\"✅ Fichier final multiclasse sauvegardé sous : kdd_full_clean_multiclass.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7900fcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typed_data_transformer_gmm import TypedDataTransformer\n",
    "import joblib\n",
    "\n",
    "# Load NSL-KDD dataset (Encoded and Important Features only)\n",
    "data = pd.read_csv('kdd_full_clean.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print('originail shape:', data.shape)\n",
    "data.head()\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "tdt = TypedDataTransformer(X)\n",
    "X_encoded = tdt.fit_transform(X)\n",
    "\n",
    "# Sauvegarder dans un fichier .pkl\n",
    "joblib.dump(tdt, \"typed_nslkdd_all_features.pkl\")\n",
    "print('originail shape:', X_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6a9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Chargement des fichiers :\n",
      "  ✅ Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv : 170366 lignes\n",
      "  ✅ Monday-WorkingHours.pcap_ISCX.csv : 529918 lignes\n",
      "  ✅ Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv : 286467 lignes\n",
      "  ✅ Tuesday-WorkingHours.pcap_ISCX.csv : 445909 lignes\n",
      "  ✅ Friday-WorkingHours-Morning.pcap_ISCX.csv : 191033 lignes\n",
      "  ✅ Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv : 225745 lignes\n",
      "  ✅ Wednesday-workingHours.pcap_ISCX.csv : 692703 lignes\n",
      "  ✅ Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv : 288602 lignes\n",
      "\n",
      "✅ Fusion totale : 2830743 lignes\n",
      "✅ Colonnes catégoriques encodées : []\n",
      "\n",
      "✅ Mapping complet (Label → target) :\n",
      "   0 → BENIGN\n",
      "   1 → Bot\n",
      "   2 → DDoS\n",
      "   3 → DoS GoldenEye\n",
      "   4 → DoS Hulk\n",
      "   5 → DoS Slowhttptest\n",
      "   6 → DoS slowloris\n",
      "   7 → FTP-Patator\n",
      "   8 → Heartbleed\n",
      "   9 → Infiltration\n",
      "  10 → PortScan\n",
      "  11 → SSH-Patator\n",
      "  12 → Web Attack � Brute Force\n",
      "  13 → Web Attack � Sql Injection\n",
      "  14 → Web Attack � XSS\n",
      "\n",
      "✅ Répartition des classes :\n",
      "Label\n",
      "BENIGN                        2273097\n",
      "DoS Hulk                       231073\n",
      "PortScan                       158930\n",
      "DDoS                           128027\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7938\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1966\n",
      "Web Attack � Brute Force         1507\n",
      "Web Attack � XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack � Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✅ Fichier sauvegardé sous : cicids2017_clean_all_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "# === Étape 1 : Chargement sécurisé et fusion ===\n",
    "folder = './cicids2017_csv_files'\n",
    "csv_files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "dataframes = []\n",
    "\n",
    "print(\"📂 Chargement des fichiers :\")\n",
    "for f in csv_files:\n",
    "    path = os.path.join(folder, f)\n",
    "    try:\n",
    "        df_temp = pd.read_csv(path)\n",
    "        dataframes.append(df_temp)\n",
    "        print(f\"  ✅ {f} : {df_temp.shape[0]} lignes\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erreur dans {f} : {e}\")\n",
    "\n",
    "# Fusion\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "print(f\"\\n✅ Fusion totale : {df.shape[0]} lignes\")\n",
    "\n",
    "# === Étape 2 : Nettoyage des noms de colonnes ===\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# === Étape 3 : Encodage des colonnes catégoriques ===\n",
    "cat_cols = ['Protocol', 'Flow ID', 'Source IP', 'Destination IP', 'Timestamp']\n",
    "cols_to_drop = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp']\n",
    "\n",
    "cat_cols = [col for col in cat_cols if col in df.columns]\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "print(f\"✅ Colonnes catégoriques encodées : {cat_cols}\")\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "# === Étape 4 : Encodage des labels ===\n",
    "if 'Label' in df.columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['target'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "    print(\"\\n✅ Mapping complet (Label → target) :\")\n",
    "    for label, idx in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "        print(f\"  {idx:2d} → {label}\")\n",
    "\n",
    "    print(\"\\n✅ Répartition des classes :\")\n",
    "    print(df['Label'].value_counts())\n",
    "\n",
    "    df.drop(columns=['Label'], inplace=True)\n",
    "else:\n",
    "    print(\"❌ La colonne 'Label' est absente du DataFrame après fusion !\")\n",
    "# === Supprimer les lignes contenant des NaN et inf ===\n",
    "df = df.dropna()\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# === Étape 5 : Sauvegarde ===\n",
    "df.to_csv(\"cicids2017_clean_all_labels.csv\", index=False)\n",
    "print(\"\\n✅ Fichier sauvegardé sous : cicids2017_clean_all_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff550586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données chargées avec succès\n",
      "Original shape: (2827876, 79)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typed_data_transformer_gmm import TypedDataTransformer\n",
    "import joblib\n",
    "\n",
    "# === Étape 1 : Charger les données nettoyées (avec classes indépendantes) ===\n",
    "data = pd.read_csv('./cicids2017_clean_all_labels.csv')\n",
    "\n",
    "print('✅ Données chargées avec succès')\n",
    "print('Original shape:', data.shape)\n",
    "\n",
    "# === Étape 2 : Séparation features / target ===\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "# === Étape 3 : Encodage intelligent avec TypedDataTransformer ===\n",
    "tdt = TypedDataTransformer(X)\n",
    "X_encoded = tdt.fit_transform(X)\n",
    "\n",
    "print('✅ Transformation typée réalisée')\n",
    "print('Encoded shape:', X_encoded.shape)\n",
    "\n",
    "# === Étape 4 : Sauvegarde du transformeur ===\n",
    "joblib.dump(tdt, \"typed_cicids2017_all_features.pkl\")\n",
    "print('✅ Transformeur sauvegardé sous : typed_cicids2017_all_features.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
