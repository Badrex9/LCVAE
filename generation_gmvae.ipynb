{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11493fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from gmvae import GMVAE\n",
    "\n",
    "# Load data\n",
    "raw_data = pd.read_csv(\"./dataset/kdd_full_clean_5classes.csv\")\n",
    "X = raw_data.drop(columns=[\"target\"])\n",
    "y = raw_data[\"target\"]\n",
    "\n",
    "# Encode features\n",
    "tdt = joblib.load(\"./typed_nslkdd_all_features.pkl\")\n",
    "X_encoded = tdt.transform(raw_data)\n",
    "\n",
    "# Split data\n",
    "_, X_test, _, y_test = train_test_split(X_encoded, y, test_size=0.3, stratify=y, random_state=42)\n",
    "encoder_label = LabelEncoder()\n",
    "y_test_encoded = encoder_label.fit_transform(y_test)\n",
    "\n",
    "# Load GMVAE\n",
    "input_dim = X_test.shape[1]\n",
    "latent_dim = 128\n",
    "n_classes = len(np.unique(y_test_encoded))\n",
    "model = GMVAE(input_dim=input_dim, latent_dim=latent_dim, n_classes=n_classes, lambda_kl=0.05)\n",
    "_ = model(tf.convert_to_tensor(X_test[:1], dtype=tf.float32))\n",
    "model.load_weights(\"./models_training/gmvae_weights.weights.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9786ce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 34.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract latent representations\n",
    "def extract_latents(model, data, batch_size):\n",
    "    latents, labels = [], []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        x_batch = data[i:i+batch_size]\n",
    "        mu, logvar, _ = model.encode(tf.convert_to_tensor(x_batch, dtype=tf.float32))\n",
    "        z = model.reparameterize(mu, logvar).numpy()\n",
    "        latents.append(z)\n",
    "    return np.concatenate(latents, axis=0)\n",
    "\n",
    "latent_vectors = extract_latents(model, X_test, batch_size=10000)\n",
    "\n",
    "# Plot (2D only)\n",
    "if latent_vectors.shape[1] == 2:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    scatter = plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], c=y_test_encoded, cmap='viridis', s=10)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(\"GMVAE Latent Space\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b450de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (148517, 42)\n",
      "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
      "0         0              1       15     9         79          0     0   \n",
      "1         0              1       20     9         69          0     0   \n",
      "2         0              0       14     9         42          0     0   \n",
      "3         0              1       49     9         76          0     0   \n",
      "4         0              0       15     9         55          0     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0               0       0    0  ...                   2   \n",
      "1               0       0    0  ...                   2   \n",
      "2               0       0    0  ...                   2   \n",
      "3               0       0    0  ...                   2   \n",
      "4               0       0    0  ...                   2   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                1.000029                0.000000   \n",
      "1                0.999984                0.000074   \n",
      "2                0.011519                0.000000   \n",
      "3                1.000057                0.016590   \n",
      "4                0.011627                0.016851   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                     1.000059                     0.000000   \n",
      "1                     1.000055                     0.000019   \n",
      "2                     1.000114                     0.000000   \n",
      "3                     1.000056                     0.000023   \n",
      "4                     1.000081                     0.000028   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0              0.000083                  0.000035              0.000000   \n",
      "1              0.000037                  0.000000              0.000062   \n",
      "2              0.000000                  0.000049              0.000043   \n",
      "3              0.000030                  0.000068              0.000046   \n",
      "4              0.000010                  0.000054              0.000054   \n",
      "\n",
      "   dst_host_srv_rerror_rate  target  \n",
      "0                  0.000019       0  \n",
      "1                  0.000012       0  \n",
      "2                  0.000014       0  \n",
      "3                  0.000020       0  \n",
      "4                  0.000015       0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Generate samples from learned priors\n",
    "# ==========================\n",
    "def generate_latent_points_from_clusters(class_distribution, center_cluster, sigma2_per_class, epsilon=1.0, seed=42):\n",
    "    \"\"\"\n",
    "    Generate latent points around each cluster center with class-specific variance.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    z_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for label, count in class_distribution.items():\n",
    "        mean = center_cluster[label]\n",
    "        stddev = np.sqrt(sigma2_per_class[label]) * epsilon\n",
    "        samples = np.random.randn(count, mean.shape[0]) * stddev + mean\n",
    "        z_list.append(samples)\n",
    "        y_list.append(np.full(count, label))\n",
    "\n",
    "    z = np.vstack(z_list)\n",
    "    y = np.concatenate(y_list)\n",
    "    return z, y\n",
    "\n",
    "# Step 1: Retrieve cluster centers and variances\n",
    "cluster_centers = model.prior_mu.numpy()\n",
    "sigma2_cluster = np.exp(model.prior_logvar.numpy())\n",
    "\n",
    "# Step 2: Class distribution from original dataset\n",
    "y_all = raw_data['target'].values\n",
    "y_all_encoded = encoder_label.transform(y_all)\n",
    "unique, counts = np.unique(y_all_encoded, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "# Step 3: Generate latent samples\n",
    "z, y_gen = generate_latent_points_from_clusters(\n",
    "    class_distribution=class_distribution,\n",
    "    center_cluster=cluster_centers,\n",
    "    sigma2_per_class=sigma2_cluster,\n",
    "    epsilon=2  # adjust alpha as needed\n",
    ")\n",
    "\n",
    "# Step 4: Decode latent samples in batches\n",
    "def decode_in_batches(model, z_array, batch_size=128):\n",
    "    decoded_batches = []\n",
    "    for i in range(0, len(z_array), batch_size):\n",
    "        z_batch = tf.convert_to_tensor(z_array[i:i+batch_size], dtype=tf.float32)\n",
    "        x_decoded = model.decode(z_batch).numpy()\n",
    "        decoded_batches.append(x_decoded)\n",
    "    return np.vstack(decoded_batches)\n",
    "\n",
    "generation_decod = decode_in_batches(model, z, batch_size=128)\n",
    "\n",
    "# Step 5: Inverse preprocessing\n",
    "Generation_real = tdt.inverse_transform(generation_decod)\n",
    "\n",
    "# Step 6: Add label column\n",
    "Generation_real = pd.DataFrame(Generation_real, columns=X.columns)\n",
    "Generation_real['target'] = encoder_label.inverse_transform(y_gen)\n",
    "\n",
    "# Step 7: Export to CSV\n",
    "print(\"Final shape:\", Generation_real.shape)\n",
    "print(Generation_real.head())\n",
    "Generation_real.to_csv('./generations/gmvae_df.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
